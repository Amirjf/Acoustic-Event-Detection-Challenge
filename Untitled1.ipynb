{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db50f7f5-75f7-490b-9d7a-3c75eafe2173",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParameterError",
     "evalue": "Audio data must be of type numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParameterError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Step 3: Extract features using compute_features_for_wave_list\u001b[39;00m\n\u001b[1;32m     29\u001b[0m wave_list_data \u001b[38;5;241m=\u001b[39m [(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m22050\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maudio_files_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \n\u001b[1;32m     30\u001b[0m                   \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m df_filtered\u001b[38;5;241m.\u001b[39miterrows()]\n\u001b[0;32m---> 31\u001b[0m keys_list, mfcc_list, hist_list, spectral_list, zcr_list, envelope_list, hnr_list \u001b[38;5;241m=\u001b[39m compute_features_for_wave_list(wave_list_data)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Step 4: Combine features\u001b[39;00m\n\u001b[1;32m     34\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([np\u001b[38;5;241m.\u001b[39mvstack(mfcc_list), np\u001b[38;5;241m.\u001b[39mvstack(hist_list), np\u001b[38;5;241m.\u001b[39mvstack(spectral_list), \n\u001b[1;32m     35\u001b[0m                np\u001b[38;5;241m.\u001b[39mvstack(zcr_list), np\u001b[38;5;241m.\u001b[39mvstack(envelope_list), np\u001b[38;5;241m.\u001b[39mvstack(hnr_list)])\n",
      "File \u001b[0;32m~/Desktop/jupyters/AML/AML-Soheil-Mina-Amir/feature_utils.py:191\u001b[0m, in \u001b[0;36mcompute_features_for_wave_list\u001b[0;34m(wave_list_data)\u001b[0m\n\u001b[1;32m    188\u001b[0m keys_list\u001b[38;5;241m.\u001b[39mappend(class_number)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Step 1: Extract MFCCs and delta MFCCs\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m mfcc_matrix \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mmfcc(y\u001b[38;5;241m=\u001b[39msound_data, sr\u001b[38;5;241m=\u001b[39msample_rate, n_mfcc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m13\u001b[39m)\n\u001b[1;32m    192\u001b[0m delta_mfcc \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mdelta(mfcc_matrix)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# Compute mean and std of MFCCs and delta MFCCs\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/librosa/feature/spectral.py:1989\u001b[0m, in \u001b[0;36mmfcc\u001b[0;34m(y, sr, S, n_mfcc, dct_type, norm, lifter, **kwargs)\u001b[0m\n\u001b[1;32m   1843\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Mel-frequency cepstral coefficients (MFCCs)\u001b[39;00m\n\u001b[1;32m   1844\u001b[0m \n\u001b[1;32m   1845\u001b[0m \u001b[38;5;124;03m.. warning:: If multi-channel audio input ``y`` is provided, the MFCC\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1985\u001b[0m \u001b[38;5;124;03m>>> fig.colorbar(img2, ax=[ax[1]])\u001b[39;00m\n\u001b[1;32m   1986\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m S \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1988\u001b[0m     \u001b[38;5;66;03m# multichannel behavior may be different due to relative noise floor differences between channels\u001b[39;00m\n\u001b[0;32m-> 1989\u001b[0m     S \u001b[38;5;241m=\u001b[39m power_to_db(melspectrogram(y\u001b[38;5;241m=\u001b[39my, sr\u001b[38;5;241m=\u001b[39msr, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[1;32m   1991\u001b[0m M: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39mfftpack\u001b[38;5;241m.\u001b[39mdct(S, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mdct_type, norm\u001b[38;5;241m=\u001b[39mnorm)[\n\u001b[1;32m   1992\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :n_mfcc, :\n\u001b[1;32m   1993\u001b[0m ]\n\u001b[1;32m   1995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lifter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1996\u001b[0m     \u001b[38;5;66;03m# shape lifter for broadcasting\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/librosa/feature/spectral.py:2130\u001b[0m, in \u001b[0;36mmelspectrogram\u001b[0;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[1;32m   2008\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmelspectrogram\u001b[39m(\n\u001b[1;32m   2009\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   2010\u001b[0m     y: Optional[np\u001b[38;5;241m.\u001b[39mndarray] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2020\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   2021\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m   2022\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute a mel-scaled spectrogram.\u001b[39;00m\n\u001b[1;32m   2023\u001b[0m \n\u001b[1;32m   2024\u001b[0m \u001b[38;5;124;03m    If a spectrogram input ``S`` is provided, then it is mapped directly onto\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2128\u001b[0m \u001b[38;5;124;03m    >>> ax.set(title='Mel-frequency spectrogram')\u001b[39;00m\n\u001b[1;32m   2129\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2130\u001b[0m     S, n_fft \u001b[38;5;241m=\u001b[39m _spectrogram(\n\u001b[1;32m   2131\u001b[0m         y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m   2132\u001b[0m         S\u001b[38;5;241m=\u001b[39mS,\n\u001b[1;32m   2133\u001b[0m         n_fft\u001b[38;5;241m=\u001b[39mn_fft,\n\u001b[1;32m   2134\u001b[0m         hop_length\u001b[38;5;241m=\u001b[39mhop_length,\n\u001b[1;32m   2135\u001b[0m         power\u001b[38;5;241m=\u001b[39mpower,\n\u001b[1;32m   2136\u001b[0m         win_length\u001b[38;5;241m=\u001b[39mwin_length,\n\u001b[1;32m   2137\u001b[0m         window\u001b[38;5;241m=\u001b[39mwindow,\n\u001b[1;32m   2138\u001b[0m         center\u001b[38;5;241m=\u001b[39mcenter,\n\u001b[1;32m   2139\u001b[0m         pad_mode\u001b[38;5;241m=\u001b[39mpad_mode,\n\u001b[1;32m   2140\u001b[0m     )\n\u001b[1;32m   2142\u001b[0m     \u001b[38;5;66;03m# Build a Mel filter\u001b[39;00m\n\u001b[1;32m   2143\u001b[0m     mel_basis \u001b[38;5;241m=\u001b[39m filters\u001b[38;5;241m.\u001b[39mmel(sr\u001b[38;5;241m=\u001b[39msr, n_fft\u001b[38;5;241m=\u001b[39mn_fft, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/librosa/core/spectrum.py:2945\u001b[0m, in \u001b[0;36m_spectrogram\u001b[0;34m(y, S, n_fft, hop_length, power, win_length, window, center, pad_mode)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2940\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ParameterError(\n\u001b[1;32m   2941\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput signal must be provided to compute a spectrogram\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2942\u001b[0m         )\n\u001b[1;32m   2943\u001b[0m     S \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2944\u001b[0m         np\u001b[38;5;241m.\u001b[39mabs(\n\u001b[0;32m-> 2945\u001b[0m             stft(\n\u001b[1;32m   2946\u001b[0m                 y,\n\u001b[1;32m   2947\u001b[0m                 n_fft\u001b[38;5;241m=\u001b[39mn_fft,\n\u001b[1;32m   2948\u001b[0m                 hop_length\u001b[38;5;241m=\u001b[39mhop_length,\n\u001b[1;32m   2949\u001b[0m                 win_length\u001b[38;5;241m=\u001b[39mwin_length,\n\u001b[1;32m   2950\u001b[0m                 center\u001b[38;5;241m=\u001b[39mcenter,\n\u001b[1;32m   2951\u001b[0m                 window\u001b[38;5;241m=\u001b[39mwindow,\n\u001b[1;32m   2952\u001b[0m                 pad_mode\u001b[38;5;241m=\u001b[39mpad_mode,\n\u001b[1;32m   2953\u001b[0m             )\n\u001b[1;32m   2954\u001b[0m         )\n\u001b[1;32m   2955\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m power\n\u001b[1;32m   2956\u001b[0m     )\n\u001b[1;32m   2958\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m S, n_fft\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/librosa/core/spectrum.py:239\u001b[0m, in \u001b[0;36mstft\u001b[0;34m(y, n_fft, hop_length, win_length, window, center, dtype, pad_mode, out)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ParameterError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhop_length=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhop_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be a positive integer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# Check audio is valid\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m util\u001b[38;5;241m.\u001b[39mvalid_audio(y, mono\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    241\u001b[0m fft_window \u001b[38;5;241m=\u001b[39m get_window(window, win_length, fftbins\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# Pad the window out to n_fft size\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/librosa/util/utils.py:295\u001b[0m, in \u001b[0;36mvalid_audio\u001b[0;34m(y, mono)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Determine whether a variable contains valid audio data.\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \n\u001b[1;32m    242\u001b[0m \u001b[38;5;124;03mThe following conditions must be satisfied:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03mnumpy.float32\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m--> 295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ParameterError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAudio data must be of type numpy.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(y\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mfloating):\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ParameterError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAudio data must be floating-point\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mParameterError\u001b[0m: Audio data must be of type numpy.ndarray"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, auc, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from feature_utils import compute_features_for_wave_list  # Use your existing function\n",
    "\n",
    "# Step 1: Load metadata and audio files\n",
    "csv_file_path = \"datasets/ESC-50-master/meta/esc50.csv\"\n",
    "audio_files_path = \"datasets/ESC-50-master/audio/\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Step 2: Define categories and sample data\n",
    "categories = {\n",
    "    'Animals': ['dog', 'cat'],\n",
    "    'Natural soundscapes & water sounds': ['toilet_flush', 'pouring_water'],\n",
    "    'Human sounds': ['snoring', 'sneezing'],\n",
    "    'Interior/domestic sounds': ['clock_alarm', 'vacuum_cleaner'],\n",
    "    'Exterior/urban noises': ['siren', 'car_horn']\n",
    "}\n",
    "selected_classes = sum(categories.values(), [])\n",
    "df_filtered = df[df['category'].isin(selected_classes)]\n",
    "\n",
    "# Step 3: Extract features using compute_features_for_wave_list\n",
    "wave_list_data = [(row['category'], row['filename'], 22050, f\"{audio_files_path}{row['filename']}\") \n",
    "                  for _, row in df_filtered.iterrows()]\n",
    "keys_list, mfcc_list, hist_list, spectral_list, zcr_list, envelope_list, hnr_list = compute_features_for_wave_list(wave_list_data)\n",
    "\n",
    "# Step 4: Combine features\n",
    "X = np.hstack([np.vstack(mfcc_list), np.vstack(hist_list), np.vstack(spectral_list), \n",
    "               np.vstack(zcr_list), np.vstack(envelope_list), np.vstack(hnr_list)])\n",
    "y = np.array(keys_list)\n",
    "\n",
    "# Step 5: Train-test split\n",
    "X_train_not_scaled, X_test_not_scaled, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Step 6: Normalize features and apply PCA (if enabled)\n",
    "normalize_features = True\n",
    "apply_pca = True\n",
    "\n",
    "if normalize_features:\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train_not_scaled)\n",
    "    X_test = scaler.transform(X_test_not_scaled)\n",
    "else:\n",
    "    X_train, X_test = X_train_not_scaled, X_test_not_scaled\n",
    "\n",
    "if apply_pca:\n",
    "    pca = PCA(n_components=10)\n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    X_test = pca.transform(X_test)\n",
    "\n",
    "# Step 7: Grid search with Stratified K-Fold\n",
    "param_grid = {'C': [0.1, 1, 10], 'gamma': ['scale'], 'kernel': ['rbf']}\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(SVC(probability=True), param_grid, scoring='roc_auc_ovr', cv=kfold, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "\n",
    "# Step 8: Train final SVM classifier\n",
    "svm = SVC(**best_params, probability=True, random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Step 9: Predictions and evaluation\n",
    "y_pred = svm.predict(X_test)\n",
    "y_prob = svm.predict_proba(X_test)\n",
    "test_auc = roc_auc_score(y_test, y_prob, multi_class='ovr')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nAUC on the test set:\", test_auc)\n",
    "print(\"\\nAccuracy on the test set:\", accuracy)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Step 10: Confusion matrix visualization\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_train), yticklabels=np.unique(y_train))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Step 11: Multi-class ROC curve\n",
    "fpr, tpr, roc_auc = {}, {}, {}\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for i, cls in enumerate(np.unique(y_train)):\n",
    "    fpr[i], tpr[i], _ = roc_curve((y_test == cls).astype(int), y_prob[:, i])\n",
    "    roc_auc[cls] = auc(fpr[i], tpr[i])\n",
    "    plt.plot(fpr[i], tpr[i], label=f\"Class {cls} (AUC = {roc_auc[cls]:.2f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label=\"Random Classifier\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multi-Class ROC Curve (One-vs-Rest)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbd7409-2b24-4480-b724-b9321d21628b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
